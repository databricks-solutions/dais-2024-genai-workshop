{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41c0a10a-f1e9-47b3-9dae-1bb0a03b0d75",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Simple RAG Example using Vector Search and the Foundation Model API\n",
    "\n",
    "[Databricks Vector Search](https://docs.databricks.com/en/generative-ai/vector-search.html) is a vector database built into Databricks that offers straightforward integration with the [Databricks Foundation Model API](https://docs.databricks.com/en/machine-learning/foundation-models/index.html) (FMAPI) embedding models.\n",
    "\n",
    "Retrieval-augmented generation (RAG) is one of the most popular application architectures for creating natural-language interfaces for people to interact with an organization's data. This notebook builds a very simple RAG application, with the following steps:\n",
    "\n",
    "1. Set up a vector index and configure it to automatically use an embedding model from the FMAPI to generate embeddings.\n",
    "1. Load some text data into the vector database\n",
    "1. Query the database\n",
    "1. Build a prompt for an LLM from the query results\n",
    "1. Query an LLM via the FMAPI, using that prompt\n",
    "\n",
    "To learn more about how Databricks Vector Search works, see the documentation [here](https://docs.databricks.com/en/generative-ai/vector-search.html#how-does-vector-search-work).\n",
    "\n",
    "For more details on querying models via the Foundation Model APIs, see the documentation [here](https://docs.databricks.com/en/machine-learning/model-serving/score-foundation-models.html#query-foundation-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1102d54c-03f9-4501-9e69-3c51d94a9ff1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "First, we will install the necessary libraries and set up a temporary catalog/schema/table for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43421aa6-1401-47d1-ac80-1d255e8db479",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall databricks-vectorsearch databricks-genai-inference\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567a035b-23ec-4f82-ac33-b6058bedecf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define catalog, table, endpoint, and index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9de74cb6-f62b-4fe6-aae9-2a0b9b19481f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = \"workspace\"\n",
    "DB='vs_demo'\n",
    "SOURCE_TABLE_NAME = \"documents\"\n",
    "SOURCE_TABLE_FULLNAME=f\"{CATALOG}.{DB}.{SOURCE_TABLE_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95cd38e-fac3-41a3-979d-ff329879e84c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Catalog, Schema, and Table\n",
    "\n",
    "A Databricks Vector Search Index is created from a Delta Table. The source Delta Table includes the data we ultimately want to index and search with the vector database. In this cell, we create the catalog, schema, and source table from which we will create the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74fa939c-ef24-4ae3-8c38-4373e255c88b",
     "showTitle": true,
     "title": "Pyspark Schema Volume Table Setup"
    }
   },
   "outputs": [],
   "source": [
    "# Set up schema/volume/table\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{DB}\")\n",
    "spark.sql(\n",
    "    f\"\"\"CREATE TABLE IF NOT EXISTS {SOURCE_TABLE_FULLNAME} (\n",
    "        id STRING,\n",
    "        text STRING,\n",
    "        date DATE,\n",
    "        title STRING\n",
    "    )\n",
    "    USING delta \n",
    "    TBLPROPERTIES ('delta.enableChangeDataFeed' = 'true')\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4e7db85-65c7-4f1a-b23f-a55203275800",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Set up the Vector Database\n",
    "Next, we set up the vector database. There are three key steps:\n",
    "1. Initialize the vector search client\n",
    "2. Create the endpoint\n",
    "3. Create the index using the source Delta table we created earlier and the `bge-large-en` embeddings model from the Foundation Model API\n",
    "\n",
    "### Initialize the Vector Search Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "638fb80d-9774-418a-8073-53ea831b6b5b",
     "showTitle": true,
     "title": "Vector Search Client Initialization"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c73400ec-2e4e-4f5b-b372-1401a43a3f71",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the Endpoint\n",
    "\n",
    "The cell below will check if the endpoint already exists and create it if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e05dcf9-7678-4622-9ef4-d3e1029fbc61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "VS_ENDPOINT_NAME = 'vs_endpoint'\n",
    "\n",
    "if vsc.list_endpoints().get('endpoints') == None or not VS_ENDPOINT_NAME in [endpoint.get('name') for endpoint in vsc.list_endpoints().get('endpoints')]:\n",
    "    print(f\"Creating new Vector Search endpoint named {VS_ENDPOINT_NAME}\")\n",
    "    vsc.create_endpoint(VS_ENDPOINT_NAME)\n",
    "else:\n",
    "    print(f\"Endpoint {VS_ENDPOINT_NAME} already exists.\")\n",
    "\n",
    "vsc.wait_for_endpoint(VS_ENDPOINT_NAME, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "869939f1-c211-4973-a3be-c99d72beea98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the Vector Index\n",
    "\n",
    "Now we can create the index over the Delta table we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ce5a7a-bd7a-43af-9af5-7793f7f81f08",
     "showTitle": true,
     "title": "Python Delta Sync Index Setup"
    }
   },
   "outputs": [],
   "source": [
    "VS_INDEX_NAME = 'fm_api_examples_vs_index'\n",
    "VS_INDEX_FULLNAME = f\"{CATALOG}.{DB}.{VS_INDEX_NAME}\"\n",
    "\n",
    "if not VS_INDEX_FULLNAME in [index.get(\"name\") for index in vsc.list_indexes(VS_ENDPOINT_NAME).get('vector_indexes', [])]:\n",
    "    try:\n",
    "        # set up an index with managed embeddings\n",
    "        print(\"Creating Vector Index...\")\n",
    "        i = vsc.create_delta_sync_index_and_wait(\n",
    "            endpoint_name=VS_ENDPOINT_NAME,\n",
    "            index_name=VS_INDEX_FULLNAME,\n",
    "            source_table_name=SOURCE_TABLE_FULLNAME,\n",
    "            pipeline_type=\"TRIGGERED\",\n",
    "            primary_key=\"id\",\n",
    "            embedding_source_column=\"text\",\n",
    "            embedding_model_endpoint_name=\"databricks-bge-large-en\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if \"INTERNAL_ERROR\" in str(e):\n",
    "            # Check if the index exists after the error occurred\n",
    "            if VS_INDEX_FULLNAME in [index.get(\"name\") for index in vsc.list_indexes(VS_ENDPOINT_NAME).get('vector_indexes', [])]:\n",
    "                print(f\"Index {VS_INDEX_FULLNAME} has been created.\")\n",
    "            else:\n",
    "                raise e\n",
    "        else:\n",
    "            raise e\n",
    "else:\n",
    "    print(f\"Index {VS_INDEX_FULLNAME} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3173bf07-4917-410c-a581-fde7fab801e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " There are a few key points to note about the specific configuration we used in this case:\n",
    "- We used `pipeline_type=\"TRIGGERED\"`. This requires us to use the index's `sync()` method to manually sync the source Delta table with the index. We could, alternatively, use `pipeline_type=\"CONTINUOUS\"` which will automatically keep the index in sync with the source table with only seconds of latency. This approach is more costly, though, as a compute cluster must be provisioned for the continuous sync streaming pipeline.\n",
    "- We specified `embedding_model_endpoint_name=\"databricks-bge-large-en\"`. We can use any embedding model available via model serving; this is the name of the pay-per-token Foundation Model API version of `databricks-bge-large-en`. By passing an `embedding_source_column` and `embedding_model_endpoint_name`, we configure the index such that it will automatically use the model to generate embeddings for the texts in the `text` column of the source table. We do not need to manually generate embeddings.\n",
    "\n",
    "  If, however, we did want to manage embeddings manually, we could include the following arguments instead:\n",
    "\n",
    "  ```\n",
    "    embedding_vector_column=\"<embedding_column>\",\n",
    "    embedding_dimension=<embedding_dimension>\n",
    "  ```\n",
    "\n",
    "  In the latter approach, we include a column for embeddings in the source delta table and embeddings are *not* computed automatically from the text column.\n",
    "\n",
    "## Set up some example texts\n",
    "\n",
    "Now we set up some example texts to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "836b179d-ef55-4ea5-b5d7-df054bf389e7",
     "showTitle": true,
     "title": "Smart Initiative: Strategic Management for Achieving Results through Efficiency and Resources"
    }
   },
   "outputs": [],
   "source": [
    "# Some example texts\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "smarter_overview = {\"text\":\"\"\"\n",
    "S.M.A.R.T.E.R. Initiative: Strategic Management for Achieving Results through Efficiency and Resources\n",
    "Introduction\n",
    "The S.M.A.R.T.E.R. Initiative, standing for \"Strategic Management for Achieving Results through Efficiency and Resources,\" is a groundbreaking project aimed at revolutionizing the way our organization operates. In today's rapidly changing business landscape, achieving success demands a strategic approach that leverages resources effectively while optimizing efficiency. The S.M.A.R.T.E.R. Initiative is designed to do just that.\n",
    "\n",
    "Background\n",
    "As markets evolve and competition intensifies, organizations must adapt to stay relevant and profitable. Traditional methods of operation often become inefficient and costly. The S.M.A.R.T.E.R. Initiative was conceived as a response to this challenge, with the primary goal of enhancing strategic management practices to achieve better results.\n",
    "\n",
    "Objectives\n",
    "1. Resource Optimization\n",
    "One of the key objectives of the S.M.A.R.T.E.R. Initiative is to optimize resource allocation. This involves identifying underutilized resources, streamlining processes, and reallocating resources to areas that contribute most to our strategic goals.\n",
    "\n",
    "2. Efficiency Improvement\n",
    "Efficiency is at the core of the S.M.A.R.T.E.R. Initiative. By identifying bottlenecks and improving processes, we aim to reduce operational costs, shorten project timelines, and enhance overall productivity.\n",
    "\n",
    "3. Strategic Alignment\n",
    "For any organization to succeed, its activities must be aligned with its strategic objectives. The S.M.A.R.T.E.R. Initiative will ensure that every action and resource allocation is in sync with our long-term strategic goals.\n",
    "\n",
    "4. Results-driven Approach\n",
    "The ultimate measure of success is results. The S.M.A.R.T.E.R. Initiative will foster a results-driven culture within our organization, where decisions and actions are guided by their impact on our bottom line and strategic objectives.\n",
    "\n",
    "Key Components\n",
    "The S.M.A.R.T.E.R. Initiative comprises several key components:\n",
    "\n",
    "1. Data Analytics and Insights\n",
    "Data is the foundation of informed decision-making. We will invest in advanced data analytics tools to gain insights into our operations, customer behavior, and market trends. These insights will guide our resource allocation and strategy.\n",
    "\n",
    "2. Process Automation\n",
    "Automation will play a vital role in enhancing efficiency. Routine and repetitive tasks will be automated, freeing up our workforce to focus on more strategic activities.\n",
    "\n",
    "3. Performance Metrics and KPIs\n",
    "To ensure that our efforts are aligned with our objectives, we will establish a comprehensive set of Key Performance Indicators (KPIs). Regular monitoring and reporting will provide visibility into our progress.\n",
    "\n",
    "4. Training and Development\n",
    "Enhancing our workforce's skills is essential. We will invest in training and development programs to equip our employees with the knowledge and tools needed to excel in their roles.\n",
    "\n",
    "Implementation Timeline\n",
    "The S.M.A.R.T.E.R. Initiative will be implemented in phases over the next three years. This phased approach allows for a smooth transition and ensures that each component is integrated effectively into our operations.\n",
    "\n",
    "Conclusion\n",
    "The S.M.A.R.T.E.R. Initiative represents a significant step forward for our organization. By strategically managing our resources and optimizing efficiency, we are positioning ourselves for sustained success in a competitive marketplace. This initiative is a testament to our commitment to excellence and our dedication to achieving exceptional results.\n",
    "\n",
    "As we embark on this journey, we look forward to the transformative impact that the S.M.A.R.T.E.R. Initiative will have on our organization and the benefits it will bring to our employees, customers, and stakeholders.\n",
    "\"\"\", \"title\": \"Project Kickoff\", \"date\": datetime.strptime(\"2024-01-16\", \"%Y-%m-%d\")}\n",
    "\n",
    "smarter_kpis = {\"text\": \"\"\"S.M.A.R.T.E.R. Initiative: Key Performance Indicators (KPIs)\n",
    "Introduction\n",
    "The S.M.A.R.T.E.R. Initiative (Strategic Management for Achieving Results through Efficiency and Resources) is designed to drive excellence within our organization. To measure the success and effectiveness of this initiative, we have established three concrete and measurable Key Performance Indicators (KPIs). This document outlines these KPIs and their associated targets.\n",
    "\n",
    "Key Performance Indicators (KPIs)\n",
    "1. Resource Utilization Efficiency (RUE)\n",
    "Objective: To optimize resource utilization for cost-efficiency.\n",
    "\n",
    "KPI Definition: RUE will be calculated as (Actual Resource Utilization / Planned Resource Utilization) * 100%.\n",
    "\n",
    "Target: Achieve a 15% increase in RUE within the first year.\n",
    "\n",
    "2. Time-to-Decision Reduction (TDR)\n",
    "Objective: To streamline operational processes and reduce decision-making time.\n",
    "\n",
    "KPI Definition: TDR will be calculated as (Pre-Initiative Decision Time - Post-Initiative Decision Time) / Pre-Initiative Decision Time.\n",
    "\n",
    "Target: Achieve a 20% reduction in TDR for critical business decisions.\n",
    "\n",
    "3. Strategic Goals Achievement (SGA)\n",
    "Objective: To ensure that organizational activities align with strategic goals.\n",
    "\n",
    "KPI Definition: SGA will measure the percentage of predefined strategic objectives achieved.\n",
    "\n",
    "Target: Achieve an 80% Strategic Goals Achievement rate within two years.\n",
    "\n",
    "Conclusion\n",
    "These three KPIs, Resource Utilization Efficiency (RUE), Time-to-Decision Reduction (TDR), and Strategic Goals Achievement (SGA), will serve as crucial metrics for evaluating the success of the S.M.A.R.T.E.R. Initiative. By tracking these KPIs and working towards their targets, we aim to drive efficiency, optimize resource utilization, and align our actions with our strategic objectives. This focus on measurable outcomes will guide our efforts towards achieving excellence within our organization.\"\"\",\n",
    "\"title\": \"Project KPIs\", \"date\": datetime.strptime(\"2024-01-16\", \"%Y-%m-%d\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df4b065c-1de5-495c-af06-0ccf53c55855",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Chunk the texts\n",
    "Typically, when using a vector database for retrieval-augmented generation (RAG) tasks, we break the texts apart into smaller (and sometimes overlapping) chunks in order to return focused and relevant information without returning an excessive amount of text.\n",
    "\n",
    "In the code below, we break the sample texts above into shorter overlapping text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12df246b-2934-457c-bf57-27628ba69cb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def chunk_text(text, chunk_size, overlap):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    index = 0\n",
    "\n",
    "    while index < len(words):\n",
    "        end = index + chunk_size\n",
    "        while end < len(words) and not re.match(r'.*[.!?]\\s*$', words[end]):\n",
    "            end += 1\n",
    "        chunk = ' '.join(words[index:end+1])\n",
    "        chunks.append(chunk)\n",
    "        index += chunk_size - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = []\n",
    "documents = [smarter_overview, smarter_kpis]\n",
    "\n",
    "for document in documents:\n",
    "    for i, c in enumerate(chunk_text(document[\"text\"], 150, 25)):\n",
    "        chunk = {}\n",
    "        chunk[\"text\"] = c\n",
    "        chunk[\"title\"] = document[\"title\"]\n",
    "        chunk[\"date\"] = document[\"date\"]\n",
    "        chunk[\"id\"] = document[\"title\"] + \"_\" + str(i)\n",
    "\n",
    "        chunks.append(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "122f2253-f981-48c0-b5af-f16a3458e0c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Insert the text chunks into the source delta table\n",
    "\n",
    "Now we save the chunks, along with some metadata (a document title, date, and a unique id) to the source delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f0388ab-064e-47dd-b8eb-3ca17ba53fcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, DateType\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"text\", StringType(), True),\n",
    "        StructField(\"title\", StringType(), True),\n",
    "        StructField(\"date\", DateType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if chunks:\n",
    "    result_df = spark.createDataFrame(chunks, schema=schema)\n",
    "    result_df.write.format(\"delta\").mode(\"append\").saveAsTable(\n",
    "        SOURCE_TABLE_FULLNAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "517ed55b-11f0-4ca0-8cb3-26a6713c31bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sync the Vector Search Index\n",
    "Because we specified `pipeline_type=\"TRIGGERED\"` when configuring the Delta Index, we still need to manually tell the index to sync with the delta table. This will take a few minutes.\n",
    "\n",
    "This will not work if the index is not ready yet. We use the `wait_until_ready` method to wait until the index is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80887325-5542-4387-a5be-c537e537ca1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sync\n",
    "index = vsc.get_index(endpoint_name=VS_ENDPOINT_NAME,\n",
    "                      index_name=VS_INDEX_FULLNAME)\n",
    "index.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da431c89-0d73-4769-ae35-4fd900528263",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query the Vector Index\n",
    "\n",
    "Now that we have added our text chunks to the source delta table and synced it with the Vector Search index, we're ready to query the index! We do this with the `index.similarity_search()` method.\n",
    "\n",
    "The `columns` argument takes a list of the columns we want returned; in this case, we request the text and title columns.\n",
    "\n",
    "**NOTE**: If the cell below does not return any results, wait a couple of minutes and try again. The index may still be syncing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2592fbd-8e26-4304-a6e8-7de1a522d489",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# query\n",
    "index.similarity_search(columns=[\"text\", \"title\"],\n",
    "                        query_text=\"What is the TDR Target for the SMARTER initiative?\",\n",
    "                        num_results = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d0adf6-37d6-4be2-ae8d-992638765ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answering Questions about the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f539c95c-7bfd-4600-b39c-169c504406ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_genai_inference import ChatSession\n",
    "\n",
    "chat = ChatSession(model=\"databricks-meta-llama-3-70b-instruct\",\n",
    "                   system_message=\"You are a helpful assistant.\",\n",
    "                   max_tokens=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4067fb4-71de-42b3-8f88-dcc027d24ba0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First, let's ask a question *without* RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "571f80ab-0d91-4965-b355-7e47ba2fac7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat.reply(\"What is the TDR Target for the SMARTER initiative?\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af5751a-9a53-4314-a836-5a913689d680",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can see, its response has nothign to do with the documents we processed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b71aacd6-b7e5-43e3-b124-e4ecff1a6590",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Now let's see what kind of reply we get when we provide context from vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11cfb944-ce14-4edd-a161-4b1224af8506",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reset history\n",
    "chat = ChatSession(model=\"databricks-meta-llama-3-70b-instruct\",\n",
    "                   system_message=\"You are a helpful assistant. Answer the user's question based on the provided context.\",\n",
    "                   max_tokens=128)\n",
    "\n",
    "# get context from vector search\n",
    "raw_context = index.similarity_search(columns=[\"text\", \"title\"],\n",
    "                        query_text=\"What is the TDR Target for the SMARTER initiative?\",\n",
    "                        num_results = 3)\n",
    "\n",
    "context_string = \"Context:\\n\\n\"\n",
    "\n",
    "for (i,doc) in enumerate(raw_context.get('result').get('data_array')):\n",
    "    context_string += f\"Retrieved context {i+1}:\\n\"\n",
    "    context_string += doc[0]\n",
    "    context_string += \"\\n\\n\"\n",
    "\n",
    "chat.reply(f\"User question: What is the TDR Target for the SMARTER initiative?\\n\\nContext: {context_string}\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c06513e-6429-4a01-8019-e774840064cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "It is now able to answer based on the provided context.\n",
    "\n",
    "### Congratulations! Demo complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58fc2348-7e79-4853-a79e-6eb8938f14d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Additional information\n",
    "\n",
    "## Using the UI\n",
    "Most of the Vector Database management steps above can be done via the UI: you can [create an endpoint](https://docs.databricks.com/en/generative-ai/create-query-vector-search.html#create-a-vector-search-endpoint-using-the-ui), [create an index](https://docs.databricks.com/en/generative-ai/create-query-vector-search.html#create-index-using-the-ui), sync the index, and more via the UI in the Databricks Catalog Explorer.\n",
    "\n",
    "## Experimenting in the AI Playground\n",
    "The [Databricks AI Playground](https://docs.databricks.com/en/large-language-models/ai-playground.html) provides a GUI for quickly experimenting with LLMs available via the FMAPI, enabling you to compare the outputs of those models and determine which model best serves your needs."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "vector_search_fm_api",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
